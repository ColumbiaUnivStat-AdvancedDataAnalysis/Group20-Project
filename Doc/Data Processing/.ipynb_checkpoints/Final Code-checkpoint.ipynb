{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing Code of Junkai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing Code of Kevin\n",
    "# Loading Data\n",
    "#Raw_Data = pd.read_csv(\"C:/Users/Kevin Zhang/OneDrive - The City University of New York/Columbia Courses/2018 Fall/GR5291 Advanced Data Analysis/Group Project/Data for ADA/Data/listings.csv\")\n",
    "Raw_Data = pd.read_csv(\"./listings.csv\")\n",
    "# Initialing Data Frame and Processing the first variable\n",
    "Processed_Data = pd.DataFrame(data = Raw_Data['host_is_superhost'])\n",
    "# Transforming the host_is_superhost into 0-1\n",
    "Processed_Data['host_is_superhost'][Processed_Data['host_is_superhost'] == 't'] = 1\n",
    "# Imputing the missing value by 0\n",
    "Processed_Data['host_is_superhost'][Processed_Data['host_is_superhost'] != 1] = 0  \n",
    "Processed_Data['host_is_superhost']\n",
    "\n",
    "# Creating property_type_df with all 0\n",
    "property_type_df = pd.DataFrame(0, columns = Raw_Data['property_type'].unique()[:-1], index = range(Processed_Data.shape[0]))\n",
    "# Transforming the host_is_superhost into 0-1\n",
    "for type in property_type_df.columns:\n",
    "    property_type_df[type][Raw_Data['property_type'] == type] = 1\n",
    "# Renaming the column names in property_type_df\n",
    "property_type_df.columns = [\"property_type_\" + str(i) for i in property_type_df.columns]\n",
    "# cbind the processed datas\n",
    "Processed_Data = pd.concat([Processed_Data, property_type_df], axis = 1)   # cbind the processed datas\n",
    "\n",
    "# cbind the availability variables\n",
    "Processed_Data = pd.concat([Processed_Data, Raw_Data['availability_30']], axis = 1)\n",
    "Processed_Data = pd.concat([Processed_Data, Raw_Data['availability_60']], axis = 1)\n",
    "Processed_Data = pd.concat([Processed_Data, Raw_Data['availability_90']], axis = 1)\n",
    "Processed_Data = pd.concat([Processed_Data, Raw_Data['availability_365']], axis = 1)\n",
    "\n",
    "# cbind the require_guest_phone_verification variables\n",
    "Processed_Data = pd.concat([Processed_Data, Raw_Data['require_guest_phone_verification']], axis = 1)\n",
    "# Transforming the host_is_superhost into 0-1\n",
    "Processed_Data['require_guest_phone_verification'][Processed_Data['require_guest_phone_verification'] == 't'] = 1\n",
    "Processed_Data['require_guest_phone_verification'][Processed_Data['require_guest_phone_verification'] == 'f'] = 0\n",
    "#Processed_Data.to_csv('Processed_Data.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing Code of Wanyi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Variables BATHROOMS\n",
    "bathrooms = pd.DataFrame(data = Raw_Data['bathrooms'])\n",
    "# Imputing the missing value by 0\n",
    "bathrooms['bathrooms'] = bathrooms['bathrooms'].replace(np.NaN, 0)\n",
    "# Combine the processed datas\n",
    "Processed_Data = pd.concat([Processed_Data, bathrooms], axis = 1)\n",
    "\n",
    "######## Variables BATHROOMS\n",
    "bedrooms = pd.DataFrame(data = Raw_Data['bedrooms'])\n",
    "# Imputing the missing value by 0\n",
    "bedrooms['bedrooms'] = bedrooms['bedrooms'].replace(np.NaN, 0)\n",
    "# Combine the processed datas\n",
    "Processed_Data = pd.concat([Processed_Data, bedrooms], axis = 1)\n",
    "\n",
    "######## Variables WEEKLY_PRICE\n",
    "weekly_price = pd.DataFrame(data = Raw_Data['weekly_price'])\n",
    "# Imputing the missing value by 0 and existing values by 1\n",
    "weekly_price['weekly_price'] = weekly_price['weekly_price'].replace(np.NaN, 0)\n",
    "weekly_price['weekly_price'][weekly_price['weekly_price'] != 0] = 1 \n",
    "# Combine the processed datas\n",
    "Processed_Data = pd.concat([Processed_Data, weekly_price], axis = 1)\n",
    "\n",
    "######## Variables MONTHLY_PRICE\n",
    "monthly_price = pd.DataFrame(data = Raw_Data['monthly_price'])\n",
    "# Imputing the missing value by 0 and existing values by 1\n",
    "monthly_price['monthly_price'] = monthly_price['monthly_price'].replace(np.NaN, 0)\n",
    "monthly_price['monthly_price'][monthly_price['monthly_price'] != 0] = 1 \n",
    "# Combine the processed datas\n",
    "Processed_Data = pd.concat([Processed_Data, monthly_price], axis = 1)\n",
    "\n",
    "# Processed_Data.to_csv('Processed_Data.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing Code of Woody"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Raw_Data\n",
    "\n",
    "# Combine the elements into a long string for further process.\n",
    "longst = data['host_verifications'][1][1: len(data['host_verifications'][1])-1]\n",
    "for i in range(1,data.shape[0]):\n",
    "    print(str(i)+'a', end = '\\r')\n",
    "    strr = data['host_verifications'][i][1: len(data['host_verifications'][i])-1]\n",
    "    longst = longst + ', ' + strr\n",
    "\n",
    "# Split the long string into a long list. Thus we successfully seperates the elements of varifications.\n",
    "longst = longst.split(', ')\n",
    "\n",
    "# Remove meaningless elements\n",
    "while '' in longst:\n",
    "    longst.remove('')\n",
    "while 'on' in longst:\n",
    "    longst.remove('on')\n",
    "\n",
    "# Create the benchmark list that contains the elements.    \n",
    "bench = pd.Series(longst).unique()\n",
    "\n",
    "# Expand the dataframe and turn the original data into dummy variables.\n",
    "n1 = len(bench)\n",
    "n0 = data.shape[0]\n",
    "varification = pd.DataFrame(0, index=range(n0), columns=bench)\n",
    "for j in range(n0):\n",
    "    print(str(j)+'b', end = '\\r')\n",
    "    hostinf = data['host_verifications'][j][1: len(data['host_verifications'][j])-1].split(', ')\n",
    "    if hostinf[0] == '' or hostinf[0] == 'on':\n",
    "        continue\n",
    "    for k in range(len(hostinf)):\n",
    "        name = hostinf[k]\n",
    "        varification[name][j] = 1\n",
    "\n",
    "# Another representation of the host_varification data. Count the number of varifications each host holds.\n",
    "vari2 = []\n",
    "for l in range(n0):\n",
    "    print(str(l)+'c', end = '\\r')\n",
    "    hostvari = data['host_verifications'][l][1: len(data['host_verifications'][l])-1].split(', ')\n",
    "    count = len(hostvari)\n",
    "    vari2.append(count)\n",
    "varification['count'] = vari2\n",
    "\n",
    "# Attach reviews_per_month variable.\n",
    "varification['reviews_per_month'] = data['reviews_per_month']\n",
    "\n",
    "# Attach cleaning_fee variable.\n",
    "for m in range(n0):\n",
    "    print(str(m)+'d', end = '\\r')\n",
    "    out = data['cleaning_fee'][m]\n",
    "    if type(out) != float:\n",
    "        data['cleaning_fee'][m] = float(out[1:])\n",
    "    else:\n",
    "        data['cleaning_fee'][m] = 0\n",
    "varification['cleaning_fee'] = data['cleaning_fee']\n",
    "\n",
    "# Combine the processed datas.\n",
    "Processed_Data = pd.concat([Processed_Data, varification], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing Code of Hongbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My variable includes: \n",
    "    # 1. extra_charge/ price ratio\n",
    "    # 2. deposits/ price ratio\n",
    "    # 3. smoke or nat.\n",
    "\n",
    "# read data\n",
    "os.chdir('/Users/hongbozhu/Desktop/5291 ADA/ADA project')\n",
    "Raw_Data=pd.read_csv('listings.csv')\n",
    "# a.head()\n",
    "    \n",
    "# Original data is something like $100.00. convert it to something like 100.00\n",
    "data['price']=data['price'].replace('[\\$,]','',regex=True).astype(float)\n",
    "data['extra_people']=data['extra_people'].replace('[\\$,]','',regex=True).astype(float)\n",
    "data['security_deposit']=data['security_deposit'].replace('[\\$,]','',regex=True).astype(float)\n",
    "\n",
    "#compute the ratios which are first two variables.\n",
    "deposits_price_ratio=data['security_deposit']/data['price']\n",
    "extra_charge_price_ratio=data['extra_people']/data['price']\n",
    "\n",
    "# the column 'house_rules' is with contex. host forbid somkes by words like \" do not smoke\",\n",
    "# \"no_smoke\", 'please don't smoke', 'smoke outside'. As long as \"smoke\" appears, smoke is not allowed.\n",
    "no_smoke=pd.to_numeric(data['house_rules'].str.contains('smoke'))\n",
    "\n",
    "# combine all columns\n",
    "Processed_Data=pd.DataFrame({'id':data['id'],\n",
    "                       'deposit_price_ratio':deposits_price_ratio,\n",
    "                       'extra_charge_price_ratio':extra_charge_price_ratio,\n",
    "                      'no_smoke':no_smoke})\n",
    "\n",
    "# some rows of price are zero. so the ratio will be infinite. convert them to missing value.\n",
    "Processed_Data[Processed_Data==np.inf]=np.nan\n",
    "Processed_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/hongbozhu/Desktop/5291 ADA/ADA project')\n",
    "Raw_Data=pd.read_csv('listings.csv')\n",
    "Processed_Data=pd.read_csv('Processed_Data.csv')\n",
    "Processed_Data.set_index('id')\n",
    "Raw_Data.set_index('id')\n",
    "Processed_Data['neighbourhood_cleansed']=Raw_Data['neighbourhood_cleansed']\n",
    "Processed_Data['review_scores_rating']=Raw_Data['review_scores_rating']\n",
    "Processed_Data.drop(['Unnamed: 0',  'Unnamed: 0.1', \n",
    "                     'id.1',  'reviews_per_month.1',\n",
    "                     'host_response_time_No_information',\n",
    "                     'host_varification_count', 'zipcode','amenities_'], axis=1,inplace=True)\n",
    "Processed_Data['host_response_rate']=pd.to_numeric(Processed_Data.host_response_rate.str.strip('%'))/100\n",
    "Processed_Data=pd.get_dummies(Processed_Data, drop_first=True)\n",
    "\n",
    "selector=Processed_Data['price']!=0 # drop rows that with price=0 which cause deposit_price_ratio Nan\n",
    "Processed_Data=Processed_Data.ix[selector,:]\n",
    "\n",
    "Processed_Data.no_smoke.fillna(0, inplace=True) \n",
    "Processed_Data.deposit_price_ratio.fillna(0, inplace=True)\n",
    "Processed_Data.dropna(inplace=True)\n",
    "Processed_Data.sort(columns='id',inplace=True)\n",
    "Processed_Data.to_csv('Processed_Data2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids=Processed_Data.id.values\n",
    "np.random.shuffle(ids)\n",
    "train_index=ids[:len(ids)//4*3]\n",
    "test_index=ids[len(ids)//4*3:]\n",
    "train_selector=[i in train_index for i in Processed_Data['id']]\n",
    "test_selector=[i in test_index for i in Processed_Data['id']]\n",
    "train=Processed_Data.iloc[train_selector,:]\n",
    "test=Processed_Data.iloc[test_selector,:]\n",
    "# train.shape, test.shape\n",
    "train.to_csv('train.csv')\n",
    "test.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
